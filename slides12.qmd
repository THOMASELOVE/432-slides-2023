---
title: "432 Class 12"
author: "<https://thomaselove.github.io/432-2023/>"
date: "2023-02-23"
date-format: iso
format: 
  beamer:
    theme: Madrid
    colortheme: lily
    fig-align: center
---

## Today's Agenda

- Using `caret` to help with k-fold cross validation
- Building a Table One
- Setting Up Quiz One

## Today's R Setup

```{r}
#| echo: true
#| message: false
knitr::opts_chunk$set(comment = NA)

library(janitor)
library(broom)
library(knitr)
library(caret)
library(tableone)
library(tidyverse)

theme_set(theme_bw()) 
```

# K-Fold Cross-Validation

## The `maleptsd` data from last time

The `maleptsd` file on our web site contains information on PTSD (post traumatic stress disorder) symptoms following childbirth for 64 fathers^[Source: Ayers et al. 2007 *J Reproductive and Infant Psychology*. The data are described in more detail in Wright DB and London K (2009) *Modern Regression Techniques Using R* Sage Publications.].  There are ten predictors and the response is a measure of PTSD symptoms. The raw, untransformed values (`ptsd_raw`) are right skewed and contain zeros, so we will work with a transformation, specifically, `ptsd = log(ptsd_raw + 1)` as our outcome, which also contains a lot of zeros. 

```{r}
#| echo: true
maleptsd <- read_csv("c11/data/maleptsd.csv", show_col_types = FALSE) |> 
  clean_names() |>
  mutate(ptsd = log(ptsd_raw + 1))
```

## Remember the problem

Only 64 observations, 10 predictors. We came up with a lasso model which used 5 of the predictors, specifically `over3`, `bond`, `neg`, `sup` and `aff`.

```{r}
#| echo: true
m1 <- lm(ptsd ~ over3 + bond + neg + sup + aff, 
         data = maleptsd)

glance(m1) |> select(r2 = r.squared, adjr2 = adj.r.squared, 
               AIC, BIC) |> kable(digits = c(4,4,2,2))
```


## Set up five-fold cross-validation

We'll use the `trainControl()` function from the **caret** package.

```{r}
#| echo: true
set.seed(43212345)
ctrl <- trainControl(method = "cv", number = 5)
```

Next, we train our model on those five folds:

```{r}
#| echo: true

ptsd_mod <- train(ptsd ~ over3 + bond + neg + sup + aff,
                  data = maleptsd, method = "lm", 
                  trControl = ctrl)
```

Results on next slide.

## `ptsd_mod` results

![](c12/figures/ptsd1.png)

Compare this to the nominal $R^2$ we saw earlier of 0.2604.

## A New Model with Two Predictors

Perhaps we can justify a two-predictor model.

```{r}
#| echo: true
m2 <- lm(ptsd ~ aff + neg, 
         data = maleptsd)

glance(m2) |> select(r2 = r.squared, adjr2 = adj.r.squared, 
               AIC, BIC) |> kable(digits = c(4,4,2,2))
```

## Train our new model on the same 5 folds

Next, we train our new model on our five folds:

```{r}
#| echo: true

ptsd_mod2 <- train(ptsd ~ neg + aff,
                  data = maleptsd, method = "lm", 
                  trControl = ctrl)
```

Results on next slide...

## `ptsd_mod2` cross-validation results

![](c12/figures/ptsd2.png)

Compare this to the nominal $R^2$ we saw earlier of 0.2025

## Model Summaries within each of the 5 folds

```{r}
#| echo: true
ptsd_mod2$resample
```

## Final Model from cross-validation

```{r}
#| echo: true

ptsd_mod2$finalModel
```

```{r}
#| echo: true
glance(ptsd_mod2$finalModel) |>
  select(r2 = r.squared, adjr2 = adj.r.squared, 
          AIC, BIC) |> kable(digits = c(4,4,2,2))
```

## Tidied Coefficients from C-V model 2

```{r}
#| echo: true

tidy(ptsd_mod2$finalModel, conf.int = TRUE, 
     conf.level = 0.90) |>
  select(term, estimate, std.error, 
         conf.low, conf.high, p.value) |>
  kable(digits = 3)
```

## Learning More about V-fold Cross-Validation

There's another example in section 16.5 of our Course Notes.

- There's more on the caret package at <https://topepo.github.io/caret/> although that's older now, and the tidymodels approach will allow us to do a lot of the same things later this term.

Can you do something similar to this with a `glm()` fit in logistic regression?

- Yes, definitely.

# Building a Table One

## An Original Clinical Investigation

![](c12/figures/bradley_title.png)

[Link to Source](https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2720923)

## Part of Bradley et al.'s Table 1

![](c12/figures/bradley_table1.png)

## Table Creation Instructions, JAMA: [linked here](https://jama.jamanetwork.com/data/ifora-forms/jama/tablecreationinst.pdf)

![](c12/figures/jama_table_instructions.png)

## A Data Set

The `bradley.csv` data set on our web site is simulated, but consists of 1,374 observations (687 Cases and 687 Controls) containing:

- a subject identification code, in `subject`
- `status` (case or control)
- age (in years)
- sex (Male or Female)
- race/ethnicity (white or non-white)
- married (1 = yes or 0 = no)
- location (ICU, bed, other)

The `bradley.csv` data closely match the summary statistics provided in Table 1 of the Bradley et al. article. Our job is to recreate that part of Table 1, as best as we can.

## The `bradley.csv` data (first 5 rows)

- The `bradley_sim.md` file on our web site shows you how I simulated the data.

![](c12/figures/bradley_csv.png)

## To "Live" Coding

On our web site (Data and Code + Class 12 materials)

- In the `data` folder:
    - `bradley.csv` data file
- `bradley_table1.Rmd` R Markdown script
- `bradley_table1.md` Results of running R Markdown
- `bradley_table1_result.csv` is the table generated by that R Markdown script

# To The "Live Code"

## Opening `bradley_table1_result.csv` in Excel

![](c12/figures/bradley_table1_result.png)

## Learning More About Table 1

Chapter 18 of the Course Notes covers two larger examples, and more details, like...

- specifying factors, and re-ordering them when necessary
- using non-normal summaries or exact categorical tests
- dealing with warning messages and with missing data
- producing Table 1 in R so you can cut and paste it into Excel or Word

FYI: Lab 05 (due 2023-03-06) requires you to build a Table 1 from data.

## Next Time

Thinking About Power: Retrospective Design

Good luck on the Quiz!
